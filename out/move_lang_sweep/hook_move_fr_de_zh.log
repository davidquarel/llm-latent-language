Command: llama_experiment_template.py --log_file out/move_lang_sweep/hook_move_fr_de_zh --src_lang fr --dest_lang zh --latent_lang de --intervention_func hook_diff_subspace --use_tuned_lens False
{'seed': 42,
 'src_lang': 'fr',
 'dest_lang': 'zh',
 'latent_lang': 'de',
 'model_size': '7b',
 'model_name': 'meta-llama/Llama-2-7b-hf',
 'single_token_only': False,
 'multi_token_only': False,
 'out_dir': './visuals',
 'hf_token': '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',
 'dataset_path': './data/synth_llama2',
 'debug': True,
 'num_multi_shot': 5,
 'token_add_spaces': True,
 'token_add_leading_byte': False,
 'token_add_prefixes': False,
 'dataset_filter_correct': True,
 'use_tuned_lens': False,
 'intervention_correct_latent_space': True,
 'steer_scale_coeff': 1.0,
 'start_layer_low': 0,
 'start_layer_high': 32,
 'end_layer_low': 0,
 'end_layer_high': 32,
 'intervention_func': 'hook_diff_subspace',
 'log_file': 'out/move_lang_sweep/hook_move_fr_de_zh',
 'metric': 'p_alt',
 'metric_goal': 'max'}
==============
def hook_diff_subspace(
    resid: Float[Tensor, "batch seq dmodel"],
    hook: HookPoint,
    model,
    latent_ids: Int[Tensor, "num_latent_tokens"] = None,
    alt_latent_ids: Int[Tensor, "num_alt_latent_tokens"] = None,
    **kwargs
) -> Float[Tensor, "batch seq dmodel"]:
    steer_scale_coeff = kwargs.get('steer_scale_coeff', None)
    assert steer_scale_coeff is not None, "steer_scale_coeff must be provided"
    subspace_latent = model.unembed.W_U.T[latent_ids]
    latent_vec = subspace_latent.mean(dim=0)
    alt_latent_vec = model.unembed.W_U.T[alt_latent_ids].mean(dim=0)
    v = resid[:, -1]
    proj_latent = proj(v.float(), subspace_latent.float()).half()
    #print(v.shape, latent_vec.shape, alt_latent_vec.shape)
    resid[:, -1] =  v - proj_latent + steer_scale_coeff * torch.linalg.norm(proj_latent) * (alt_latent_vec - latent_vec)
    return resid

==============

Measuring 
lp_out/p_out : logprobs/probs of correct answer
lp_alt/p_alt logprobs/probs of alternate answer
lp_diff/p_ratio: logprob_diff/probs ration of alt-correct or alt/correct

==============
size of dataset: 54size of correct dataset: 36Command: llama_experiment_template.py --log_file out/move_lang_sweep/hook_move_fr_de_zh --src_lang fr --dest_lang zh --latent_lang de --intervention_func hook_diff_subspace --use_tuned_lens False
{'seed': 42,
 'src_lang': 'fr',
 'dest_lang': 'zh',
 'latent_lang': 'de',
 'model_size': '7b',
 'model_name': 'meta-llama/Llama-2-7b-hf',
 'single_token_only': False,
 'multi_token_only': False,
 'out_dir': './visuals',
 'hf_token': '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',
 'dataset_path': './data/synth_llama2',
 'debug': True,
 'num_multi_shot': 5,
 'token_add_spaces': True,
 'token_add_leading_byte': False,
 'token_add_prefixes': False,
 'dataset_filter_correct': True,
 'use_tuned_lens': False,
 'intervention_correct_latent_space': True,
 'steer_scale_coeff': 1.0,
 'start_layer_low': 0,
 'start_layer_high': 32,
 'end_layer_low': 0,
 'end_layer_high': 32,
 'intervention_func': 'hook_diff_subspace',
 'log_file': 'out/move_lang_sweep/hook_move_fr_de_zh',
 'metric': 'p_alt',
 'metric_goal': 'max'}
==============
def hook_diff_subspace(
    resid: Float[Tensor, "batch seq dmodel"],
    hook: HookPoint,
    model,
    latent_ids: Int[Tensor, "num_latent_tokens"] = None,
    alt_latent_ids: Int[Tensor, "num_alt_latent_tokens"] = None,
    **kwargs
) -> Float[Tensor, "batch seq dmodel"]:
    steer_scale_coeff = kwargs.get('steer_scale_coeff', None)
    assert steer_scale_coeff is not None, "steer_scale_coeff must be provided"
    subspace_latent = model.unembed.W_U.T[latent_ids]
    latent_vec = subspace_latent.mean(dim=0)
    alt_latent_vec = model.unembed.W_U.T[alt_latent_ids].mean(dim=0)
    v = resid[:, -1]
    proj_latent = proj(v.float(), subspace_latent.float()).half()
    #print(v.shape, latent_vec.shape, alt_latent_vec.shape)
    resid[:, -1] =  v - proj_latent + steer_scale_coeff * torch.linalg.norm(proj_latent) * (alt_latent_vec - latent_vec)
    return resid

==============

Measuring 
lp_out/p_out : logprobs/probs of correct answer
lp_alt/p_alt logprobs/probs of alternate answer
lp_diff/p_ratio: logprob_diff/probs ration of alt-correct or alt/correct

==============
size of dataset: 54size of correct dataset: 39